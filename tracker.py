"""í•­ê³µê¶Œ ê°€ê²© íŠ¸ë˜ì»¤ - í¬ë¡¤ëŸ¬ + DB ì €ì¥ + ì¦‰ì‹œ ì•Œë¦¼"""

import asyncio
import random
import re
import subprocess
import urllib.request
import urllib.error
import json as _json
import ssl as _ssl
import logging
from datetime import datetime, timedelta

import pytz
from playwright.async_api import async_playwright

from config import (
    ROUTES, TRIP_PATTERNS, SCAN_WEEKS, SPECIAL_DATES,
    NAVER_FLIGHT_URL, REQUEST_DELAY_MIN, REQUEST_DELAY_MAX, MAX_RETRIES,
    DISCORD_CHANNEL_ID, DEPART_TIME_FROM, RETURN_TIME_FROM,
)
from db import (init_db, get_db, insert_scan, update_weekly_lowest,
                insert_price_snapshot, insert_weekly_price_snapshot)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger(__name__)

KST = pytz.timezone("Asia/Seoul")

DESTINATION_LABELS = {r["destination"]: r["label"] for r in ROUTES}


def generate_scan_dates() -> list[tuple[str, str]]:
    """ê¸ˆìš”ì¼ ì¶œë°œ â†’ ì¼ìš”ì¼ ê·€êµ­, 12ì£¼ì¹˜ ë‚ ì§œ ìŒì„ ìƒì„±í•œë‹¤."""
    today = datetime.now(KST).date()
    dates = []

    for pattern in TRIP_PATTERNS:
        depart_wd = pattern["depart_weekday"]
        return_wd = pattern["return_weekday"]
        trip_length = (return_wd - depart_wd) % 7

        # ê°€ì¥ ê°€ê¹Œìš´ ì¶œë°œ ìš”ì¼ ì°¾ê¸°
        days_ahead = (depart_wd - today.weekday()) % 7
        if days_ahead == 0 and today.weekday() == depart_wd:
            # ì˜¤ëŠ˜ì´ ì¶œë°œ ìš”ì¼ì´ë©´ í¬í•¨
            next_depart = today
        else:
            next_depart = today + timedelta(days=days_ahead)

        # ì´ë¯¸ ì§€ë‚œ ë‚ ì§œë©´ ë‹¤ìŒ ì£¼ë¡œ
        if next_depart < today:
            next_depart += timedelta(days=7)

        for week in range(SCAN_WEEKS):
            depart = next_depart + timedelta(weeks=week)
            ret = depart + timedelta(days=trip_length)
            dates.append((depart.strftime("%Y%m%d"), ret.strftime("%Y%m%d")))

    # íŠ¹ë³„ ì¼ì • ì¶”ê°€ (ê³¼ê±° ë‚ ì§œ ì œì™¸, ì¤‘ë³µ ì œì™¸)
    existing = set(dates)
    for dep, ret in SPECIAL_DATES:
        from datetime import date
        dep_date = date(int(dep[:4]), int(dep[4:6]), int(dep[6:]))
        if dep_date >= today and (dep, ret) not in existing:
            dates.append((dep, ret))

    return dates


def build_url(origin: str, destination: str, depart_date: str, return_date: str,
              adults: int = 1) -> str:
    url = NAVER_FLIGHT_URL.format(
        origin=origin,
        destination=destination,
        depart_date=depart_date,
        return_date=return_date,
    )
    if adults != 1:
        url = url.replace("adult=1", f"adult={adults}")
    return url


_token_result = subprocess.run(
    ["openclaw", "config", "get", "channels.discord.token"],
    capture_output=True, text=True
)
DISCORD_BOT_TOKEN = _token_result.stdout.strip()


def send_discord(message: str):
    """Discord REST APIë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•œë‹¤."""
    url = f"https://discord.com/api/v10/channels/{DISCORD_CHANNEL_ID}/messages"
    payload = _json.dumps({"content": message}).encode("utf-8")
    req = urllib.request.Request(
        url,
        data=payload,
        headers={
            "Authorization": f"Bot {DISCORD_BOT_TOKEN}",
            "Content-Type": "application/json",
            "User-Agent": "mc-mini-flight-tracker/1.0",
        },
        method="POST",
    )
    ssl_ctx = _ssl.create_default_context()
    ssl_ctx.check_hostname = False
    ssl_ctx.verify_mode = _ssl.CERT_NONE
    try:
        with urllib.request.urlopen(req, timeout=30, context=ssl_ctx) as resp:
            if resp.status in (200, 201):
                logger.info("Discord ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
            else:
                logger.error(f"Discord ì „ì†¡ ì‹¤íŒ¨: HTTP {resp.status}")
    except urllib.error.HTTPError as e:
        logger.error(f"Discord ì „ì†¡ ì‹¤íŒ¨: HTTP {e.code} {e.read().decode()}")
    except Exception as e:
        logger.error(f"Discord ì „ì†¡ ì‹¤íŒ¨: {e}")


def format_price_alert(destination: str, depart_date: str, return_date: str,
                       old_price, new_price: int, airline: str, flight_info: str,
                       overall_min: int | None = None,
                       overall_min_date: str | None = None) -> str:
    """ìµœì €ê°€ ê°±ì‹  ì¦‰ì‹œ ì•Œë¦¼ ë©”ì‹œì§€ë¥¼ ìƒì„±í•œë‹¤."""
    label = DESTINATION_LABELS.get(destination, destination)
    dd = datetime.strptime(depart_date, "%Y-%m-%d")
    rd = datetime.strptime(return_date, "%Y-%m-%d")
    weekdays_kr = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    dd_str = f"{dd.month:02d}/{dd.day:02d}({weekdays_kr[dd.weekday()]})"
    rd_str = f"{rd.month:02d}/{rd.day:02d}({weekdays_kr[rd.weekday()]})"

    lines = [f"ğŸš¨ ìµœì €ê°€ ê°±ì‹ ! ì¸ì²œ â†’ {label}"]
    lines.append(f"ğŸ“… {dd_str} â†’ {rd_str}")

    if old_price is not None:
        diff_pct = (new_price - old_price) / old_price * 100
        lines.append(f"ì´ì „: {old_price:,}ì› â†’ í˜„ì¬: {new_price:,}ì› ({diff_pct:+.1f}%)")
    else:
        lines.append(f"í˜„ì¬: {new_price:,}ì›")

    lines.append(f"í•­ê³µì‚¬: {airline}")

    # flight_infoì—ì„œ ê°€ëŠ” í¸/ì˜¤ëŠ” í¸ íŒŒì‹±
    if " / " in flight_info:
        out_leg, ret_leg = flight_info.split(" / ", 1)
        lines.append(f"â†— ê°€ëŠ”í¸: {out_leg.strip()}")
        lines.append(f"â†™ ì˜¤ëŠ”í¸: {ret_leg.strip()}")
    else:
        lines.append(flight_info)

    # ì „ì²´ ìµœì €ê°€ í‘œì‹œ
    if overall_min is not None:
        if overall_min_date:
            omd = datetime.strptime(overall_min_date, "%Y-%m-%d")
            omd_str = f"{omd.month:02d}/{omd.day:02d}({weekdays_kr[omd.weekday()]})"
            lines.append(f"ğŸ“Š êµ¬ê°„ ì „ì²´ ìµœì €ê°€: {overall_min:,}ì› ({omd_str} ì¶œë°œ)")
        else:
            lines.append(f"ğŸ“Š êµ¬ê°„ ì „ì²´ ìµœì €ê°€: {overall_min:,}ì›")

    return "\n".join(lines)


def parse_naver_flights(text: str, origin: str, destination: str,
                        depart_time_from: int, return_time_from: int) -> dict | None:
    """main ìš”ì†Œì˜ innerTextë¥¼ ì¤„ ë‹¨ìœ„ë¡œ íŒŒì‹±í•˜ì—¬ í•­ê³µí¸ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.

    í•­ê³µì‚¬ëª… â†’ (ì´ë²¤íŠ¸í˜œíƒ?) â†’ HH:MMICN â†’ HH:MMDEST â†’ ì§í•­, ... íŒ¨í„´ì„ ì°¾ë˜
    ê°€ëŠ” í¸/ì˜¤ëŠ” í¸ í•­ê³µì‚¬ê°€ ë‹¤ë¥¸ ì¡°í•©(í˜¼í•© ì˜ˆì•½)ë„ ì²˜ë¦¬í•œë‹¤.

    Returns:
        {
            "min_price": int,
            "airline": str,
            "flight_info": str,
            "kal_price": int | None,
            "kal_flight_info": str | None,
        }
    """
    # í•­ê³µì‚¬ëª…ìœ¼ë¡œ ì˜ëª» ì¸ì‹í•˜ë©´ ì•ˆ ë˜ëŠ” ë©”íƒ€ ë¼ì¸
    META_KEYWORDS = {"ì´ë²¤íŠ¸í˜œíƒ", "ê³µë™ìš´í•­", "ë™ì¼ê°€", "íŠ¹ê°€í™•ì¸", "ì•Œë¦¼ë°›ê¸°"}

    def is_meta(s: str) -> bool:
        return any(kw in s for kw in META_KEYWORDS) or s.strip() in {"í• ì¸", " í• ì¸"}

    def is_airline_name(s: str) -> bool:
        if is_meta(s):
            return False
        if re.search(r"\d", s):
            return False
        if not re.match(r"^[ê°€-í£a-zA-Z\sÂ·,]+$", s):
            return False
        return 2 <= len(s) <= 30

    lines = [l.strip() for l in text.split("\n") if l.strip()]

    depart_out_pat = re.compile(rf"\d{{2}}:\d{{2}}{re.escape(origin)}")
    depart_ret_pat = re.compile(rf"\d{{2}}:\d{{2}}{re.escape(destination)}")

    results = []
    i = 0
    while i < len(lines):
        # ê°€ëŠ” í¸ ì¶œë°œ íŒ¨í„´: HH:MMICN
        if not depart_out_pat.match(lines[i]):
            i += 1
            continue

        # lines[i]   = HH:MMICN (ê°€ëŠ” í¸ ì¶œë°œ)
        # lines[i+1] = HH:MMDEST (ê°€ëŠ” í¸ ë„ì°©)
        # lines[i+2] = "ì§í•­, ..." or "ê²½ìœ ..."
        if i + 2 >= len(lines):
            i += 1
            continue

        depart_hour = int(lines[i][:2])
        is_out_direct = "ì§í•­" in lines[i + 2] and "ê²½ìœ " not in lines[i + 2]

        if not is_out_direct:
            i += 1
            continue

        # ê°€ëŠ” í¸ ì§í•­ í™•ì¸. ì˜¤ëŠ” í¸ ì¶œë°œ HH:MMDEST íƒìƒ‰ (ë‹¤ìŒ 15ì¤„ ë‚´)
        ret_start = None
        for j in range(i + 3, min(i + 18, len(lines))):
            if depart_ret_pat.match(lines[j]):
                if j + 2 < len(lines) and "ì§í•­" in lines[j + 2] and "ê²½ìœ " not in lines[j + 2]:
                    ret_start = j
                    break

        if ret_start is None:
            i += 1
            continue

        return_hour = int(lines[ret_start][:2])

        # ì‹œê°„ ì¡°ê±´ ì²´í¬
        if depart_hour < depart_time_from or return_hour < return_time_from:
            i += 1
            continue

        # í•­ê³µì‚¬: lines[i] ì´ì „ì„ ì—­ë°©í–¥ìœ¼ë¡œ íƒìƒ‰ (ë©”íƒ€ ë¼ì¸ ê±´ë„ˆëœ€)
        airline = "ê¸°íƒ€"
        for k in range(i - 1, max(i - 6, -1), -1):
            if is_airline_name(lines[k]):
                airline = lines[k]
                break

        # ë™ì¼ í•­ê³µì‚¬ ì™•ë³µ í•„í„°: ê°€ëŠ” í¸ ë„ì°©(i+1)ê³¼ ì˜¤ëŠ” í¸ ì¶œë°œ(ret_start) ì‚¬ì´ì—
        # ë‹¤ë¥¸ í•­ê³µì‚¬ëª…ì´ ìˆìœ¼ë©´ í˜¼í•© ì¡°í•© â†’ ìŠ¤í‚µ
        is_mixed = False
        for k in range(i + 3, ret_start):
            if is_airline_name(lines[k]) and lines[k] != airline:
                is_mixed = True
                break
        if is_mixed:
            i += 1
            continue

        # ê°€ê²© ì°¾ê¸°: ì˜¤ëŠ” í¸ ì§í•­ ì¤„ ì´í›„ 15ì¤„ ë‚´ì—ì„œ "ì™•ë³µ XXXì›" íŒ¨í„´
        price = None
        for j in range(ret_start + 3, min(ret_start + 18, len(lines))):
            m = re.search(r"ì™•ë³µ\s*([\d,]+)ì›", lines[j])
            if m:
                price = int(m.group(1).replace(",", ""))
                break

        if not price:
            i += 1
            continue

        flight_info = (
            f"{lines[i][:5]} {origin}â†’{destination} {lines[i+1][:5]} / "
            f"{lines[ret_start][:5]} {destination}â†’{origin} {lines[ret_start+1][:5]}"
        )
        results.append({
            "airline": airline,
            "price": price,
            "flight_info": flight_info,
        })

        i = ret_start + 3  # ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ

    if not results:
        return None

    # ìµœì €ê°€ ì°¾ê¸°
    best = min(results, key=lambda x: x["price"])

    # KAL ì°¾ê¸° (ì™•ë³µ ëª¨ë‘ ëŒ€í•œí•­ê³µì¸ ì¡°í•© â€” í•­ê³µì‚¬ëª…ì— "ëŒ€í•œí•­ê³µ" í¬í•¨)
    kal = next((r for r in results if "ëŒ€í•œí•­ê³µ" in r["airline"]), None)

    return {
        "min_price": best["price"],
        "airline": best["airline"],
        "flight_info": best["flight_info"],
        "kal_price": kal["price"] if kal else None,
        "kal_flight_info": kal["flight_info"] if kal else None,
    }


async def scrape_flights(page, url: str, origin: str, destination: str,
                         depart_time_from: int, return_time_from: int) -> dict | None:
    """ë„¤ì´ë²„ í•­ê³µê¶Œ í˜ì´ì§€ì—ì„œ í•­ê³µí¸ ì •ë³´ë¥¼ í¬ë¡¤ë§í•œë‹¤."""
    try:
        await page.goto(url, wait_until="domcontentloaded", timeout=60000)
        await page.wait_for_timeout(8000)

        text = await page.evaluate(
            '() => { const m = document.querySelector("main"); return m ? m.innerText : ""; }'
        )

        if not text or len(text) < 100:
            logger.warning(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë‚´ìš© ë¶€ì¡±: {url}")
            return None

        return parse_naver_flights(text, origin, destination, depart_time_from, return_time_from)

    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì˜¤ë¥˜ ({url}): {e}")
        return None


async def scan_route(page, route_id: int, origin: str, destination: str,
                     dates: list[tuple[str, str]]):
    """í•œ êµ¬ê°„ì˜ ì „ì²´ ë‚ ì§œë¥¼ ìŠ¤ìº”í•œë‹¤."""
    db = await get_db()
    try:
        route_cursor = await db.execute(
            "SELECT depart_time_from, return_time_from FROM routes WHERE id = ?",
            (route_id,),
        )
        route_row = await route_cursor.fetchone()
        depart_time_from = route_row[0] if isinstance(route_row, tuple) else route_row["depart_time_from"]
        return_time_from = route_row[1] if isinstance(route_row, tuple) else route_row["return_time_from"]

        for depart_date, return_date in dates:
            url = build_url(origin, destination, depart_date, return_date)
            dd_fmt = f"{depart_date[:4]}-{depart_date[4:6]}-{depart_date[6:]}"
            rd_fmt = f"{return_date[:4]}-{return_date[4:6]}-{return_date[6:]}"
            logger.info(f"ìŠ¤ìº”: {origin}â†’{destination} {dd_fmt} ~ {rd_fmt}")

            result = None
            for attempt in range(MAX_RETRIES + 1):
                result = await scrape_flights(
                    page, url, origin, destination,
                    depart_time_from, return_time_from,
                )
                if result is not None:
                    break
                if attempt < MAX_RETRIES:
                    logger.info(f"ì¬ì‹œë„ ({attempt + 1}/{MAX_RETRIES})")
                    await asyncio.sleep(2)

            if result is None:
                logger.warning(f"ê²°ê³¼ ì—†ìŒ: {origin}â†’{destination} {dd_fmt}")
                # ê¸°ì¡´ weekly_lowest ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚­ì œ (í¬ë¡¤ëŸ¬ê°€ ë°ì´í„° ê´€ë¦¬ ë‹´ë‹¹)
                existing = await db.execute(
                    "SELECT id FROM weekly_lowest WHERE route_id=? AND depart_date=? AND return_date=?",
                    (route_id, dd_fmt, rd_fmt)
                )
                if await existing.fetchone():
                    await db.execute(
                        "DELETE FROM weekly_lowest WHERE route_id=? AND depart_date=? AND return_date=?",
                        (route_id, dd_fmt, rd_fmt)
                    )
                    await db.commit()
                    logger.info(f"weekly_lowest ì‚­ì œ: {origin}â†’{destination} {dd_fmt} (í•­ê³µí¸ ì†Œë©¸)")
                await asyncio.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))
                continue

            now = datetime.now(KST).isoformat()

            # scan_history ì €ì¥
            await insert_scan(
                db, route_id, dd_fmt, rd_fmt,
                result["min_price"], result["airline"],
                result["flight_info"], now,
            )

            # weekly_lowest ê°±ì‹ 
            price_change = await update_weekly_lowest(
                db, route_id, dd_fmt, rd_fmt,
                result["min_price"], result["airline"], result["flight_info"],
                result["kal_price"], result["kal_flight_info"], now,
            )

            await db.commit()

            # ìµœì €ê°€ ê°±ì‹  ì‹œ ì¦‰ì‹œ ì•Œë¦¼
            if price_change is not None:
                old_price, new_price = price_change
                if old_price is not None:  # ê¸°ì¡´ ëŒ€ë¹„ ê°±ì‹ ëœ ê²½ìš°ë§Œ ì•Œë¦¼
                    # í•´ë‹¹ êµ¬ê°„ ì „ì²´ ìµœì €ê°€ ì¡°íšŒ
                    overall_row = await db.execute(
                        "SELECT MIN(min_price) as p, depart_date FROM weekly_lowest WHERE route_id=?",
                        (route_id,)
                    )
                    overall = await overall_row.fetchone()
                    overall_min = overall["p"] if overall else None
                    overall_min_date = overall["depart_date"] if overall else None

                    alert_msg = format_price_alert(
                        destination, dd_fmt, rd_fmt,
                        old_price, new_price,
                        result["airline"], result["flight_info"],
                        overall_min=overall_min,
                        overall_min_date=overall_min_date,
                    )
                    send_discord(alert_msg)

            # ëœë¤ ë”œë ˆì´
            delay = random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX)
            await asyncio.sleep(delay)

    finally:
        await db.close()


async def cleanup_past_dates():
    """ì˜¤ëŠ˜ ì´ì „ ë‚ ì§œì˜ weekly_lowest í–‰ì„ ì‚­ì œí•˜ê³ , 30ì¼ ì´ìƒ ëœ scan_historyë¥¼ ì •ë¦¬í•œë‹¤."""
    db = await get_db()
    today_str = datetime.now(KST).date().isoformat()  # "YYYY-MM-DD"
    cutoff_str = (datetime.now(KST).date() - timedelta(days=30)).isoformat()
    try:
        # weekly_lowest ê³¼ê±° ë‚ ì§œ ì‚­ì œ
        cursor = await db.execute(
            "SELECT COUNT(*) FROM weekly_lowest WHERE depart_date < ?",
            (today_str,)
        )
        count = (await cursor.fetchone())[0]
        if count > 0:
            await db.execute(
                "DELETE FROM weekly_lowest WHERE depart_date < ?",
                (today_str,)
            )
            logger.info(f"weekly_lowest ê³¼ê±° ë‚ ì§œ {count}ê±´ ì‚­ì œ (< {today_str})")
        else:
            logger.info("ì‚­ì œí•  weekly_lowest ê³¼ê±° ë‚ ì§œ ì—†ìŒ")

        # scan_history 30ì¼ ì´ìƒ ëœ ë°ì´í„° ì‚­ì œ
        cursor2 = await db.execute(
            "SELECT COUNT(*) FROM scan_history WHERE scanned_at < ?",
            (cutoff_str,)
        )
        count2 = (await cursor2.fetchone())[0]
        if count2 > 0:
            await db.execute(
                "DELETE FROM scan_history WHERE scanned_at < ?",
                (cutoff_str,)
            )
            logger.info(f"scan_history 30ì¼+ ë°ì´í„° {count2}ê±´ ì‚­ì œ (< {cutoff_str})")

        await db.commit()
    finally:
        await db.close()


async def check_pax3_prices(page):
    """êµ¬ê°„ë³„ ì „ì²´ ìµœì €ê°€ ì£¼ë¥¼ adult=3ìœ¼ë¡œ í¬ë¡¤ë§í•´ pax3_priceë¥¼ ê°±ì‹ í•œë‹¤."""
    db = await get_db()
    try:
        for i, route in enumerate(ROUTES, start=1):
            origin = route["origin"]
            destination = route["destination"]
            depart_time_from = route.get("depart_time_from", DEPART_TIME_FROM)
            return_time_from = route.get("return_time_from", RETURN_TIME_FROM)

            # í•´ë‹¹ êµ¬ê°„ì˜ í˜„ì¬ ìµœì €ê°€ ì£¼ ì¡°íšŒ
            row = await db.execute(
                "SELECT depart_date, return_date, min_price FROM weekly_lowest "
                "WHERE route_id = ? ORDER BY min_price ASC LIMIT 1",
                (i,)
            )
            best = await row.fetchone()
            if not best:
                continue

            dep = best["depart_date"].replace("-", "")
            ret = best["return_date"].replace("-", "")
            url = build_url(origin, destination, dep, ret, adults=3)

            logger.info(f"3ì¸ ê°€ê²© ì²´í¬: {origin}â†’{destination} {best['depart_date']} (adult=3)")
            result = await scrape_flights(page, url, origin, destination,
                                         depart_time_from, return_time_from)
            await asyncio.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))

            pax3_price = result["min_price"] if result else None
            await db.execute(
                "UPDATE weekly_lowest SET pax3_price = ? "
                "WHERE route_id = ? AND depart_date = ? AND return_date = ?",
                (pax3_price, i, best["depart_date"], best["return_date"])
            )
            if pax3_price is not None:
                logger.info(f"3ì¸ 1ì¸ë‹¹: {pax3_price:,}ì› (1ì¸: {best['min_price']:,}ì›)")
            else:
                logger.warning(f"3ì¸ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {origin}â†’{destination} {best['depart_date']}")

        await db.commit()
    finally:
        await db.close()


async def main():
    logger.info("í•­ê³µê¶Œ ê°€ê²© íŠ¸ë˜ì»¤ ì‹œì‘")

    await init_db()
    await cleanup_past_dates()
    dates = generate_scan_dates()
    logger.info(f"ìŠ¤ìº” ë‚ ì§œ {len(dates)}ê°œ ìƒì„±ë¨")

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=False,
            args=["--no-sandbox", "--disable-blink-features=AutomationControlled"]
        )
        context = await browser.new_context(
            user_agent=(
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/131.0.0.0 Safari/537.36"
            ),
            viewport={"width": 1280, "height": 800},
            locale="ko-KR",
        )
        await context.add_init_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        page = await context.new_page()

        for i, route in enumerate(ROUTES, start=1):
            logger.info(f"êµ¬ê°„ ìŠ¤ìº” ì‹œì‘: {route['origin']}â†’{route['destination']} ({route['label']})")
            await scan_route(page, i, route["origin"], route["destination"], dates)
            logger.info(f"êµ¬ê°„ ìŠ¤ìº” ì™„ë£Œ: {route['label']}")

        # êµ¬ê°„ë³„ ìµœì €ê°€ ì£¼ 3ì¸ ê°€ê²© í™•ì¸
        try:
            await check_pax3_prices(page)
        except Exception as e:
            logger.error(f"3ì¸ ê°€ê²© ì²´í¬ ì‹¤íŒ¨: {e}")

        await browser.close()

    # ìŠ¤ëƒ…ìƒ· ê¸°ë¡ â€” ì‹¤íŒ¨í•´ë„ exportëŠ” ê³„ì†
    try:
        await record_snapshots()
    except Exception as e:
        logger.error(f"ìŠ¤ëƒ…ìƒ· ê¸°ë¡ ì‹¤íŒ¨ (exportëŠ” ê³„ì† ì§„í–‰): {e}")

    # data.json ë‚´ë³´ë‚´ê¸° + GitHub push â€” ì‹¤íŒ¨í•´ë„ ìŠ¤ìº” ê²°ê³¼ëŠ” DBì— ë³´ì¡´ë¨
    try:
        await export_and_push()
    except Exception as e:
        logger.error(f"export_and_push ì‹¤íŒ¨: {e}")

    logger.info("í•­ê³µê¶Œ ê°€ê²© íŠ¸ë˜ì»¤ ì™„ë£Œ")


async def record_snapshots():
    """ì „ì²´ weekly_lowest ê¸°ì¤€ìœ¼ë¡œ price_history / weekly_price_history ìŠ¤ëƒ…ìƒ·ì„ ê¸°ë¡í•œë‹¤."""
    db = await get_db()
    now_str = datetime.now(KST).isoformat()
    try:
        rows = await db.execute(
            "SELECT route_id, depart_date, return_date, min_price, airline, flight_info "
            "FROM weekly_lowest ORDER BY route_id, min_price"
        )
        rows = await rows.fetchall()

        # êµ¬ê°„ë³„ ì „ì²´ ìµœì €ê°€ (min_price ê¸°ì¤€ ì²« ë²ˆì§¸ row)
        seen_routes = set()
        for row in rows:
            rid = row["route_id"]
            if rid not in seen_routes:
                seen_routes.add(rid)
                await insert_price_snapshot(
                    db, rid, now_str,
                    row["min_price"], row["airline"],
                    row["depart_date"], row["flight_info"]
                )
            # ì£¼ë³„ ìŠ¤ëƒ…ìƒ·
            await insert_weekly_price_snapshot(
                db, rid, row["depart_date"], row["return_date"],
                now_str, row["min_price"], row["airline"], row["flight_info"]
            )
        await db.commit()
        logger.info(f"ìŠ¤ëƒ…ìƒ· ê¸°ë¡ ì™„ë£Œ ({len(rows)}ê°œ ì£¼)")
    finally:
        await db.close()


async def export_and_push():
    """DB â†’ data.json ë‚´ë³´ë‚´ê¸° í›„ GitHubì— pushí•œë‹¤.

    ë°©ì–´ ì„¤ê³„:
    - ë©”ì¸ ì¿¼ë¦¬(weekly_lowest) ì‹¤íŒ¨ â†’ ì˜ˆì™¸ ì „íŒŒ (data.json ë¯¸ì‘ì„±)
    - íˆìŠ¤í† ë¦¬ ì¿¼ë¦¬ ì‹¤íŒ¨ â†’ ê²½ê³  ë¡œê·¸ë§Œ, ë¹ˆ íˆìŠ¤í† ë¦¬ë¡œ data.json ì •ìƒ ì‘ì„±
    - data.json ì‘ì„±ì€ DB ì—°ê²° ì¢…ë£Œ í›„ í•­ìƒ ì‹¤í–‰ (finally ì™¸ë¶€)
    - git push ì‹¤íŒ¨ â†’ ë¡œê·¸ë§Œ (íŒŒì¼ì€ ì´ë¯¸ ì €ì¥ë¨)
    """
    import pathlib
    HISTORY_LIMIT = 200

    data = {"updated_at": datetime.now(KST).isoformat(), "routes": []}
    route_map = {}

    db = await get_db()
    try:
        # â”€â”€ 1. ë©”ì¸ ë°ì´í„°: weekly_lowest (ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ì „íŒŒ)
        route_labels = {r["destination"]: r["label"] for r in ROUTES}
        rows = await db.execute("""
            SELECT r.origin, r.destination,
                   w.depart_date, w.return_date,
                   w.min_price, w.airline, w.flight_info,
                   w.kal_price, w.kal_flight_info,
                   w.pax3_price, w.updated_at
            FROM weekly_lowest w
            JOIN routes r ON w.route_id = r.id
            ORDER BY r.id, w.depart_date
        """)
        async for row in rows:
            key = f"{row['origin']}-{row['destination']}"
            if key not in route_map:
                route_map[key] = {
                    "origin": row["origin"],
                    "destination": row["destination"],
                    "label": route_labels.get(row["destination"], row["destination"]),
                    "weeks": [],
                    "overall_history": [],
                    "weekly_history": {},
                }
            route_map[key]["weeks"].append({
                "depart_date": row["depart_date"],
                "return_date": row["return_date"],
                "min_price": row["min_price"],
                "airline": row["airline"],
                "flight_info": row["flight_info"],
                "kal_price": row["kal_price"],
                "kal_flight_info": row["kal_flight_info"],
                "pax3_price": row["pax3_price"],
                "updated_at": row["updated_at"],
            })
        data["routes"] = list(route_map.values())

        # â”€â”€ 2. íˆìŠ¤í† ë¦¬ ë°ì´í„°: ì‹¤íŒ¨í•´ë„ ë©”ì¸ ë°ì´í„°ëŠ” ë³´ì¡´
        rid_to_key = {
            i + 1: f"{r['origin']}-{r['destination']}"
            for i, r in enumerate(ROUTES)
        }
        try:
            ph_rows = await db.execute(
                "SELECT route_id, snapshot_at, overall_min_price, airline, depart_date "
                "FROM price_history ORDER BY route_id, snapshot_at DESC"
            )
            ph_by_route: dict = {}
            for row in await ph_rows.fetchall():
                key = rid_to_key.get(row["route_id"])
                if key and key in route_map:
                    ph_by_route.setdefault(key, []).append({
                        "snapshot_at": row["snapshot_at"],
                        "price": row["overall_min_price"],
                        "airline": row["airline"],
                        "depart_date": row["depart_date"],
                    })
            for key, entries in ph_by_route.items():
                route_map[key]["overall_history"] = list(reversed(entries[:HISTORY_LIMIT]))

            wph_rows = await db.execute(
                "SELECT route_id, depart_date, snapshot_at, min_price, airline "
                "FROM weekly_price_history ORDER BY route_id, depart_date, snapshot_at DESC"
            )
            wph_by_key: dict = {}
            for row in await wph_rows.fetchall():
                key = rid_to_key.get(row["route_id"])
                if key and key in route_map:
                    dd = row["depart_date"]
                    wph_by_key.setdefault(key, {}).setdefault(dd, []).append({
                        "snapshot_at": row["snapshot_at"],
                        "price": row["min_price"],
                        "airline": row["airline"],
                    })
            for key, dd_map in wph_by_key.items():
                wh = route_map[key]["weekly_history"]
                for dd, entries in dd_map.items():
                    wh[dd] = list(reversed(entries[:HISTORY_LIMIT]))

        except Exception as e:
            logger.warning(f"íˆìŠ¤í† ë¦¬ ì¿¼ë¦¬ ì‹¤íŒ¨ (ë¹ˆ íˆìŠ¤í† ë¦¬ë¡œ ì§„í–‰): {e}")

    finally:
        await db.close()

    repo_dir = pathlib.Path(__file__).parent
    data_path = repo_dir / "data.json"
    with open(data_path, "w", encoding="utf-8") as f:
        _json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"data.json ì €ì¥ ì™„ë£Œ ({len(data['routes'])}ê°œ êµ¬ê°„)")

    try:
        subprocess.run(["git", "-C", str(repo_dir), "add", "data.json"], check=True)
        result = subprocess.run(
            ["git", "-C", str(repo_dir), "diff", "--cached", "--quiet"],
            capture_output=True
        )
        if result.returncode != 0:  # ë³€ê²½ì‚¬í•­ ìˆì„ ë•Œë§Œ ì»¤ë°‹
            now_str = datetime.now(KST).strftime("%Y-%m-%d %H:%M KST")
            subprocess.run(
                ["git", "-C", str(repo_dir), "commit", "-m", f"data: {now_str} ê°€ê²© ì—…ë°ì´íŠ¸"],
                check=True
            )
            subprocess.run(["git", "-C", str(repo_dir), "push"], check=True)
            logger.info("GitHub push ì™„ë£Œ")
        else:
            logger.info("ë³€ê²½ì‚¬í•­ ì—†ìŒ, push ìƒëµ")
    except subprocess.CalledProcessError as e:
        logger.error(f"GitHub push ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    asyncio.run(main())
